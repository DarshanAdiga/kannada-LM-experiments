{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite: https://github.com/AI4Bharat/indic-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'sop_classifier.classifier.weight', 'predictions.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.bias', 'sop_classifier.classifier.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai4bharat/indic-bert\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "kn_base_dir = base_dir + 'indicnlp-news-articles/kn/'\n",
    "train_file = kn_base_dir + 'kn-train.csv'\n",
    "test_file = kn_base_dir + 'kn-test.csv'\n",
    "valid_file = kn_base_dir + 'kn-valid.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b318d9e5241e7c69\n",
      "Reusing dataset csv (/home/jupyter-admin/.cache/huggingface/datasets/csv/default-b318d9e5241e7c69/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'sentence'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'sentence'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'sentence'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "dataset = load_dataset('csv', column_names=['label', 'sentence'], data_files={'train': train_file, 'test': test_file, 'validation': valid_file})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_attributes = [k for k,v in dataset.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sports': 0, 'entertainment': 1, 'lifestyle': 2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5064393e5c4ffb8c0dc3038ccf67ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f63f6aa6b045e3af473928e06b2b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6deed3c51e6c4c05adf1574608e26532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d4408bcd0e481d9856ebe5b9623938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a6af6609594e699cfadb080ca6b54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2dda51bf1f432db76ddc4b1473af59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Class labeling & update the dataset\n",
    "class_names = {l for l in dataset[\"train\"][\"label\"]}\n",
    "class_dict = {c:i for i,c in enumerate(class_names)}\n",
    "print(class_dict)\n",
    "\n",
    "def class_to_id(row):\n",
    "    row[\"label\"] = class_dict[row[\"label\"]]\n",
    "    return row\n",
    "\n",
    "for attr in dataset_attributes:\n",
    "    ds_attr = dataset[attr]\n",
    "    # Overwrite the label column after converting string to int\n",
    "    ds_attr = ds_attr.map(class_to_id)\n",
    "    # Type cast the lable column\n",
    "    new_features = ds_attr.features.copy()\n",
    "    new_features[\"label\"] = ClassLabel(names=list(class_names))\n",
    "    ds_attr = ds_attr.cast(new_features)\n",
    "    dataset[attr] = ds_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(num_classes=3, names=['sports', 'entertainment', 'lifestyle'], names_file=None, id=None),\n",
       " 'sentence': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fc45b8b32a48e58f486baac28000ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d1a69fa32f4021b8e9a819b8a01c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140196a258c84db89bcd0fd14568c3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'sentence', 'token_type_ids'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'sentence', 'token_type_ids'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'sentence', 'token_type_ids'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "MAX_LENGTH=512\n",
    "def tokenize_function(row):\n",
    "    return tokenizer(row['sentence'], truncation=True, max_length=MAX_LENGTH)\n",
    "                         \n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the unwanted columns\n",
    "for attr in dataset_attributes:\n",
    "    ds_attr = tokenized_datasets[attr]\n",
    "    ds_attr = ds_attr.remove_columns([\"sentence\"])\n",
    "    tokenized_datasets[attr] = ds_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collator\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attention_mask': torch.Size([5, 506]),\n",
       " 'input_ids': torch.Size([5, 506]),\n",
       " 'token_type_ids': torch.Size([5, 506]),\n",
       " 'labels': torch.Size([5])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attention_mask': torch.Size([5, 512]),\n",
       " 'input_ids': torch.Size([5, 512]),\n",
       " 'token_type_ids': torch.Size([5, 512]),\n",
       " 'labels': torch.Size([5])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attention_mask': torch.Size([5, 512]),\n",
       " 'input_ids': torch.Size([5, 512]),\n",
       " 'token_type_ids': torch.Size([5, 512]),\n",
       " 'labels': torch.Size([5])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (Optional) Check the dimensions\n",
    "for attr in dataset_attributes:\n",
    "    print(attr)\n",
    "    samps = tokenized_datasets[attr][:5]\n",
    "    batch = data_collator(samps)\n",
    "    display({k: v.shape for k, v in batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning on Classification objective\n",
    "from transformers import TrainingArguments, Trainer\n",
    "CLS_MODEL_DIR = base_dir + 'model_cp_01'\n",
    "TRAINING_STEPS=400000\n",
    "EVALUATION_STEPS=10000\n",
    "CHECKPOINT_SAVE_STEPS=5000\n",
    "training_args = TrainingArguments(CLS_MODEL_DIR)\n",
    "training_args = TrainingArguments(CLS_MODEL_DIR, \n",
    "                                  max_steps=TRAINING_STEPS,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  eval_steps=EVALUATION_STEPS,\n",
    "                                  save_steps=CHECKPOINT_SAVE_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer instance\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 24000\n",
      "  Num Epochs = 134\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210913' max='400000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210913/400000 17:12:11 < 15:25:23, 3.41 it/s, Epoch 70.30/134]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.162879</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.964283</td>\n",
       "      <td>0.964272</td>\n",
       "      <td>0.964333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.182240</td>\n",
       "      <td>0.957667</td>\n",
       "      <td>0.957525</td>\n",
       "      <td>0.957699</td>\n",
       "      <td>0.957667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.971778</td>\n",
       "      <td>0.972428</td>\n",
       "      <td>0.971667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.106062</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.975322</td>\n",
       "      <td>0.975502</td>\n",
       "      <td>0.975333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.113259</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.976334</td>\n",
       "      <td>0.976402</td>\n",
       "      <td>0.976333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.175414</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.965249</td>\n",
       "      <td>0.966288</td>\n",
       "      <td>0.965333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.139934</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.971038</td>\n",
       "      <td>0.971097</td>\n",
       "      <td>0.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.121687</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.971725</td>\n",
       "      <td>0.972314</td>\n",
       "      <td>0.971667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.973049</td>\n",
       "      <td>0.973232</td>\n",
       "      <td>0.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.164783</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.973909</td>\n",
       "      <td>0.974493</td>\n",
       "      <td>0.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.155488</td>\n",
       "      <td>0.969000</td>\n",
       "      <td>0.968940</td>\n",
       "      <td>0.968949</td>\n",
       "      <td>0.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.137686</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.976332</td>\n",
       "      <td>0.976445</td>\n",
       "      <td>0.976333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.161873</td>\n",
       "      <td>0.972333</td>\n",
       "      <td>0.972382</td>\n",
       "      <td>0.972531</td>\n",
       "      <td>0.972333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.147202</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.973965</td>\n",
       "      <td>0.974546</td>\n",
       "      <td>0.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.162855</td>\n",
       "      <td>0.972333</td>\n",
       "      <td>0.972367</td>\n",
       "      <td>0.972693</td>\n",
       "      <td>0.972333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.145647</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.973050</td>\n",
       "      <td>0.973173</td>\n",
       "      <td>0.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.151570</td>\n",
       "      <td>0.974333</td>\n",
       "      <td>0.974368</td>\n",
       "      <td>0.974440</td>\n",
       "      <td>0.974333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.137912</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>0.977022</td>\n",
       "      <td>0.977359</td>\n",
       "      <td>0.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.168830</td>\n",
       "      <td>0.973667</td>\n",
       "      <td>0.973630</td>\n",
       "      <td>0.974101</td>\n",
       "      <td>0.973667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.137842</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.975353</td>\n",
       "      <td>0.975576</td>\n",
       "      <td>0.975333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.152728</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.976333</td>\n",
       "      <td>0.976545</td>\n",
       "      <td>0.976333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-25000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-25000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-25000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-35000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-35000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-35000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-45000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-45000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-45000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-55000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-55000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-55000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-65000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-65000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-65000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-75000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-75000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-75000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-85000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-85000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-85000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-95000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-95000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-95000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-105000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-105000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-105000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-115000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-115000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-115000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-125000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-125000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-125000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-210000\n",
      "Configuration saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-210000/config.json\n",
      "Model weights saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-210000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-210000/tokenizer_config.json\n",
      "Special tokens file saved in /home/sphi/work/darshan/kn-work/indicBERT-runs/classification-task/model_cp_01/checkpoint-210000/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('GPU Available:{}'.format(torch.cuda.is_available()))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and Predict on the test data\n",
    "from transformers import pipeline\n",
    "model = AutoModelForSequenceClassification.from_pretrained(CLS_MODEL_DIR + '/checkpoint-400000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Below two cells are not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test data loader\n",
    "# from torch.utils.data import DataLoader\n",
    "# test_data_loader = DataLoader(tokenized_datasets[\"test\"], shuffle=False, batch_size=8, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the predictions on Test dataset\n",
    "# for batch in test_data_loader:\n",
    "#     predictions = model(**batch)\n",
    "#     #TODO Accumulate the predictions here\n",
    "#     print(predictions.loss, predictions.logits.shape)\n",
    "#     break\n",
    "\n",
    "# def evaluate(predictions):\n",
    "#     labels = pred.label_ids\n",
    "#     preds = pred.predictions.argmax(-1)\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "#     acc = accuracy_score(labels, preds)\n",
    "#     return {\n",
    "#         'accuracy': acc,\n",
    "#         'f1': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.9273571372032166}, {'label': 'LABEL_0', 'score': 0.9998754262924194}, {'label': 'LABEL_1', 'score': 0.9997266530990601}]\n",
      "Labels for reference: {'lifestyle': 0, 'entertainment': 1, 'sports': 2}\n"
     ]
    }
   ],
   "source": [
    "# Sample predictions\n",
    "classifer_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "# Use the sentences from original test dataset\n",
    "test_data = [\n",
    "    \"ಹೂಡಿಕೆ ಮಾಡಿದ ಹಣ ಹೆಚ್ಚು ವೇಗವಾಗಿ ಬೆಳೆಯುತ್ತದೆ ಎಂಬುದರಲ್ಲಿ ಅನುಮಾನ ಬೇಡ.\",\n",
    "    \"ಹೀಗಾಗಿ ಈಗ ಸಕ್ರಿಯೆ ರಾಜಕೀಯಕ್ಕೆ ಬಂದಿದ್ದಾರೆ ಎಂದು ರಾಹುಲ್ ಹೇಳಿದ್ದಾರೆ.\",\n",
    "    \"ಟೆನ್ ಬೈ ಫೋರ‍್ಟೀನ್‌ ಹಾಲ್‌ಗೆ ನಾನು ಕೆಮ್ಮುತ್ತಾ ಪ್ರವೇಶಿಸುತ್ತಿದ್ದಂತೆಯೇ ಅಲ್ಲಿದ್ದ ಎಲ್ಲರೂ ಅಲರ್ಟ್ ಆದರು.\"\n",
    "]\n",
    "result = classifer_pipeline(test_data)\n",
    "print(result)\n",
    "print('Labels for reference:', class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_VENV",
   "language": "python",
   "name": "torch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
